<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CS184 Homework 1</title>
    <link rel="stylesheet" href="style.css">
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
        }

        header {
            background-color: #007bff;
            color: #ffffff;
            padding: 20px;
            text-align: center;
        }

        section {
            margin: 20px;
            padding: 20px;
            background-color: #ffffff;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        h2 {
            color: #007bff;
        }

        table {
            width: 100%;
            border-collapse: collapse;
        }

        table,
        th,
        td {
            border: 1px solid #ddd;
        }

        th,
        td {
            padding: 10px;
            text-align: left;
        }

        th {
            background-color: #f4f4f4;
        }

        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 10px auto;
        }

        .img-gallery {
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 10px;
        }

        .img-gallery img {
            width: calc(25% - 10px);
        }

        @media screen and (max-width: 600px) {
            .img-gallery img {
                width: calc(50% - 10px);
            }
        }
    </style>
</head>

<body>
    <header>
        <h1>CS184 Homework 1</h1>
    </header>

    <section id="task1">
        <h2>Task 1: Triangle Rasterization</h2>
        <h3>Bounding Box</h3>
        <section id="task1">
            <h2>Task 1: Triangle Rasterization</h2>
            <h3>Bounding Box Method</h3>
            <p>
                Initially, we implemented the Basic Bounding Box method. For a given triangle, we determine the minimum
                and
                maximum x and y coordinates to identify the bounding box. This box encompasses all potential pixels for
                rasterization. We then iterate over each pixel within this box, employing line equations to ascertain
                whether a
                pixel lies within the triangle. Pixels inside the triangle are subsequently colored.
            </p>
            <p>
                To prevent the bounding box from extending beyond the display area, we clamp its coordinates to the
                dimensions
                of the screen. Moreover, we optimize memory usage by reversing the order of iteration in our loops,
                thereby
                enhancing cache efficiency.
            </p>
            <h3>Scanline Algorithm</h3>
            <p>
                Following the bounding box method, we adopted the Scanline algorithm, which begins by sorting the
                triangle's
                vertices based on their y coordinates. This algorithm divides the triangle into an upper and a lower
                section.
                For each section, we calculate where the horizontal scanlines intersect the triangle's edges and fill in
                the
                pixels spanning these intersections.
            </p>
            <p>
                The Scanline algorithm is notably more efficient than its bounding box counterpart, as it only processes
                pixels
                within the triangle. However, this efficiency comes at the cost of increased complexity, including the
                need to
                sort the vertices.
            </p>
        </section>

        <img src="./imgs/task1_2.png" alt="Task 1 Screenshot" style="width: 500px;">


        <h3>Rendering Times Comparison</h3>
        <p>
            Debug build, repeat 10 times:
        </p>
        <table>
            <tr>
                <th>Test Case</th>
                <th>Basic Bounding Box (s)</th>
                <th>Swap X,Y Basic Bounding Box (s)</th>
                <th>Scanline (s)</th>
            </tr>
            <tr>
                <td>Basic 1</td>
                <td>0.011928</td>
                <td>0.012152</td>
                <td>0.006026</td>
            </tr>
            <tr>
                <td>Basic 2</td>
                <td>0.044396</td>
                <td>0.04534</td>
                <td>0.044267</td>
            </tr>
            <tr>
                <td>Basic 3</td>
                <td>0.013392</td>
                <td>0.013052</td>
                <td>0.01282</td>
            </tr>
            <tr>
                <td>Basic 4</td>
                <td>0.003251</td>
                <td>0.0032</td>
                <td>0.001767</td>
            </tr>
            <tr>
                <td>Basic 5</td>
                <td>0.00134</td>
                <td>0.0013</td>
                <td>0.001341</td>
            </tr>
            <tr>
                <td>Basic 6</td>
                <td>0.006447</td>
                <td>0.006631</td>
                <td>0.003268</td>
            </tr>
            <tr>
                <td>Basic 7</td>
                <td>0.085573</td>
                <td>0.084135</td>
                <td>0.046709</td>
            </tr>
            <tr>
                <td>Basic 8</td>
                <td>0.084978</td>
                <td>0.085336</td>
                <td>0.08602</td>
            </tr>
        </table>
        The Scanline algorithm generally outperforms the Basic Bounding Box approach in terms of speed. However,
        optimizing
        the Bounding Box by swapping loops does not yield a significant performance improvement, possibly due to the
        relatively small size of the dataset.
        </p>
        <!-- <img src="path/to/task1_screenshot.png" alt="Task 1 Screenshot"> -->
    </section>

    <section id="task2">

        <h2>Task 2: Supersampling</h2>
        <p>
            Supersampling enhances image quality by rendering the scene at a higher resolution and then averaging
            these
            samples for each final pixel, effectively smoothing out jagged edges and improving overall image
            fidelity.
        </p>
        <p>
            The primary data structure for this task is a 2D array named <code>sample_buffer</code>. We increase the
            width
            and height of <code>sample_buffer</code> according to the square of the supersampling rate. The triangle
            is
            projected into the supersampled space (scaling x and y coordinates by the supersampling rate). We then
            iterate
            through the triangle's bounding box in this space, filling <code>sample_buffer</code> with the
            triangle's color,
            similar to the approach in Task 1.
        </p>
        <p>
            Once <code>sample_buffer</code> is populated, we process each pixel by averaging the colors of the
            supersampled
            pixels within <code>sample_buffer</code> to determine the final color on the screen.
        </p>
        <p>Modified functions:</p>
        <ul>
            <li><code>set_sample_rate</code>: Adjusts the size of <code>sample_buffer</code> to account for the
                supersampling rate, effectively resizing to width * height * rate.</li>
            <li><code>resolve_to_framebuffer</code>: Iterates through the pixels in a supersampled area, computes
                the
                average color from the supersampled pixels, and assigns this color to the target framebuffer.</li>
            <li><code>rasterize_triangle</code>: Projects the triangle into the supersampled space and populates
                <code>sample_buffer</code> with the color of the triangle.
            </li>
        </ul>



        <div class="img-row-single">
            <img src="./imgs/task2_1.png" alt="Task 2 Screenshot">
            <img src="./imgs/task2_2.png" alt="Task 2 Screenshot">
            <img src="./imgs/task2_3.png" alt="Task 2 Screenshot">
            <img src="./imgs/task2_4.png" alt="Task 2 Screenshot">
        </div>

        <p>
            The supersampled image exhibits noticeably smoother edges, particularly on the slender portions of the
            triangle,
            compared to the original. As the supersampling rate increases, pixels on the edges appear more transparent.
            This
            transparency effect arises because each pixel's color represents the average of multiple samples. For pixels
            partially covered by the triangle, their color blends with the background. Consequently, pixels covering
            only a
            minor portion of the triangle tend to show increased transparency.
        </p>


    </section>
    <section id="task3">
        <h2>Task 3: Cubeman Animation</h2>
        <p>
            We designed an animation featuring a robot standing on one foot, achieved by rotating the lower part of its
            left
            foot. To simulate the appearance of maintaining balance, both arms were rotated and positioned accordingly.
            Additionally, the head was tilted downwards to enhance the overall effect of the robot's pose.
        </p>
        <div class="img-gallery">
            <img src="./imgs/task3.png" alt="Task 3 Screenshot" style="width: 500px;">
        </div>
        <!-- <img src="path/to/task3_screenshot.png" alt="Task 3 Screenshot"> -->
    </section>

    <section id="task4">
        <h2>Task 4: Barycentric Coordinates</h2>
        <p>
            Barycentric coordinates provide a method for specifying locations within a triangle relative to its
            vertices. They
            reveal the proportion of each vertex's influence at any given point inside the triangle. Utilizing
            barycentric
            interpolation, we can smoothly blend the colors of the triangle's vertices across its entire area, achieving
            a
            gradient effect.
        </p>
        <p>
            The color observed at any point inside the triangle is a composite of the vertex colors, weighted by the
            point's
            proximity to each vertex. Thus, a point's closeness to a particular vertex amplifies the contribution of
            that
            vertex's color to the final mix, allowing for a nuanced color transition within the triangle.
        </p>
        <div class="img-gallery">
            <img src="./imgs/task4.png" alt="Task 4 Screenshot">
            <img src="./imgs/task4_2.png" alt="Task 4 Screenshot">
        </div>
    </section>

    <section id="task5">
        <h2>Pixel Sampling</h2>
        <p>
            Pixel sampling is a critical technique for determining pixel colors within a scene. It establishes a
            correspondence
            between each scene point and a specific location in UV space. Given the discrete nature of UV textures,
            pixel
            sampling techniques dictate the approach for extracting color information from these textures.
        </p>
        <p>
            The process begins with identifying the UV coordinates for a point, achieved through barycentric
            interpolation based
            on the UV coordinates of a triangle's vertices. These UV coordinates are then translated into texture space
            coordinates, which serve as a reference for color sampling from the UV texture.
        </p>
        <p>
            Nearest neighbor sampling selects the color of the closest texture pixel.
            While fast,
            this approach may lead to aliasing due to its abrupt color transitions. Alternatively, bilinear sampling,
            which
            involves linear interpolation among the four closest texture pixels, offers smoother transitions and can
            reduce
            aliasing effects.
        </p>
        <div class="img-gallery">
            <img src="./imgs/51.png" alt="Task 2 Screenshot">
            <img src="./imgs/52.png" alt="Task 2 Screenshot">
        </div>
        <div class="img-gallery">
            <img src="./imgs/53.png" alt="Task 2 Screenshot">
            <img src="./imgs/54.png" alt="Task 2 Screenshot">
        </div>

        <p>
            The images on the left utilize nearest neighbor sampling, whereas those on the right employ bilinear
            sampling. The
            first row displays results from 1x sampling, and the second row from 16x sampling.
        </p>
        <p>
            In the 1x sampled images, bilinear sampling yields a smoother texture than nearest neighbor sampling, which
            exhibits
            more pronounced aliasing. This difference arises because nearest neighbor sampling selects the color of the
            closest
            pixel, potentially overlooking finer texture details like thin lines. Bilinear sampling, by averaging the
            colors of
            the four nearest pixels, can more accurately represent these details, reducing aliasing and resulting in a
            smoother
            appearance.
        </p>
        <p>
            At 16x sampling, the distinction between the two methods becomes negligible. The increased number of samples
            inherently smooths the texture, diminishing the impact of the sampling technique on the final image quality.
        </p>

    </section>

    <section id="task6">
        <h2>Task 6: Level Sampling</h2>
        <p>
            Level sampling, integral to Mipmapping in texture mapping, enhances texture quality by adjusting the detail
            level
            based on the object's distance from the camera. This technique mitigates aliasing by applying
            lower-resolution
            textures to distant objects and higher-resolution textures to closer ones.
        </p>

        <h3>Speed</h3>
        <p>
            Comparing pixel sampling methods, nearest neighbor sampling outpaces bilinear sampling by approximately 15%.
            This
            speed advantage stems from nearest neighbor sampling's simplicity—only the closest pixel's color is needed,
            as
            opposed to bilinear sampling, which interpolates the colors of the four nearest pixels.
        </p>
        <p>
            Among level sampling strategies, L_ZERO outperforms L_NEAREST by about 10% and L_LINEAR by roughly 20% in my
            implementation. L_NEAREST and L_LINEAR's slower speeds are due to their additional computations—rounding to
            the
            nearest level and interpolating between two levels, respectively.
        </p>
        <p>
            The number of samples per pixel significantly influences rendering speed, with increases in sample count
            leading to
            proportional decreases in performance. This correlation is primarily because more samples necessitate more
            texture
            sampling operations.
        </p>

        <h3>Memory Usage</h3>
        <p>
            Memory consumption is relatively uniform across pixel sampling techniques. However, level sampling demands
            extra
            memory for storing mipmaps. Additionally, the sample count per pixel directly impacts memory requirements,
            especially for framebuffer storage.
        </p>

        <h3>Antialiasing Power</h3>
        <p>
            Bilinear sampling achieves basic antialiasing by softening color transitions. L_NEAREST and L_LINEAR further
            enhance
            antialiasing by adapting texture detail levels, with L_LINEAR slightly outperforming L_NEAREST in smoothing
            2D image
            edges. In contrast, nearest neighbor sampling and L_ZERO level sampling do not contribute to antialiasing.
        </p>
        <p>
            The antialiasing effect intensifies with the number of samples per pixel, leading to smoother textures.
            However,
            beyond 4x sampling, improvements in antialiasing become less noticeable.
        </p>

        <div class="img-row">
            <img src="./imgs/0n.png" alt="Task 6 Screenshot">
            <img src="./imgs/0l.png" alt="Task 6 Screenshot">
        </div>
        <div class="img-row">
            <img src="./imgs/nn.png" alt="Task 6 Screenshot">
            <img src="./imgs/nl.png" alt="Task 6 Screenshot">
        </div>
        <p>
            The images display varying effects on the texture of my cat's fur, attributed to different combinations of
            level and
            pixel sampling methods. The top-left image, using L_ZERO with P_NEAREST, shows no antialiasing effect,
            resulting in
            a more rugged texture. Conversely, the top-right image, combining L_ZERO with P_LINEAR, presents a smoother
            appearance due to the linear interpolation of pixel colors.
        </p>
        <p>
            The bottom-left image, featuring L_NEAREST with P_NEAREST, distorts the fur texture, potentially due to the
            mismatch
            between the texture detail level and the sampling precision. The bottom-right image, which pairs L_NEAREST
            with
            P_LINEAR, exhibits an overly smoothed, somewhat blurry effect on the fur, indicating that the linear
            interpolation
            at this level of detail might be too aggressive, reducing the texture's natural sharpness.
        </p>

    </section>

</body>

</html>